from typing import Dict, List, Optional, TypedDict, Annotated
from langgraph.graph import StateGraph, END, START
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from gms_client import GMSClient
from ai.app.models.bert_emotion import BERTEmotionDetector
import json
from datetime import datetime
import operator
import time

class EnhancedConversationState(TypedDict):
    """ê°•í™”ëœ ëŒ€í™” ìƒíƒœ ê´€ë¦¬"""
    user_input: str
    personality_scores: Dict[str, float]
    active_personas: List[str]
    discussion_history: Annotated[List[Dict], operator.add]
    inference_steps: Annotated[List[Dict], operator.add]
    current_round: int
    max_rounds: int
    waiting_for_user: bool
    follow_up_questions: List[str]
    summary: str
    conversation_complete: bool
    persona_interactions: Dict[str, List[str]]  # í˜ë¥´ì†Œë‚˜ ê°„ ìƒí˜¸ì‘ìš© ì¶”ì 

class EnhancedBig5PersonaAgent:
    """ê°œì„ ëœ Big5 í˜ë¥´ì†Œë‚˜ ì—ì´ì „íŠ¸ - ì¤‘ë³µ ë°©ì§€ ë° ëª…í™•í•œ ì—­í• """
    
    def __init__(self, gms_client: GMSClient, trait_name: str, trait_code: str):
        self.gms_client = gms_client
        self.trait_name = trait_name
        self.trait_code = trait_code
        self.character_traits = self._define_character()
        self.previous_points = []  # ì´ì „ì— í•œ ë§ ê¸°ë¡
    
    def _define_character(self) -> Dict:
        """ê° í˜ë¥´ì†Œë‚˜ì˜ ê³ ìœ í•œ ìºë¦­í„°ì™€ ì—­í•  ì •ì˜"""
        characters = {
            "E": {
                "name": "ì™¸í–¥ì„±",
                "emoji": "ğŸŒŸ",
                "personality": "ì—ë„ˆì§€ ë„˜ì¹˜ëŠ” í™œë™ê°€",
                "unique_perspective": "ì‚¬íšŒì  ê´€ê³„ì™€ í™œë™ì„±",
                "speaking_patterns": ["íŒì„ ë²Œì´ì!", "í•¨ê»˜í•˜ë©´ ë” ê°•í•´ì ¸!", "ì•ì— ë‚˜ì„œëŠ” í˜ì´ ìˆì–´!"],
                "focus_questions": ["ëˆ„êµ¬ì™€ í•¨ê»˜í•  ìˆ˜ ìˆì„ê¹Œ?", "ì–´ë–»ê²Œ ë” ì ê·¹ì ìœ¼ë¡œ?", "ì‚¬ëŒë“¤ê³¼ ì–´ë–»ê²Œ ì†Œí†µí• ê¹Œ?"],
                "avoid_topics": ["í˜¼ì í•´ê²°í•˜ê¸°", "ë‚´ì„±ì  ì ‘ê·¼"]
            },
            "A": {
                "name": "ì¹œí™”ì„±", 
                "emoji": "ğŸ¤",
                "personality": "ë”°ëœ»í•œ í˜‘ë ¥ì",
                "unique_perspective": "ê´€ê³„ ì¡°í™”ì™€ í˜‘ë ¥",
                "speaking_patterns": ["ì„œë¡œ ì´í•´í•´ë³´ì", "í˜‘ë ¥í•˜ë©´ ë” ì¢‹ì•„ì ¸", "ìƒëŒ€ë°© ì…ì¥ì—ì„œëŠ”"],
                "focus_questions": ["ì–´ë–»ê²Œ ê°ˆë“±ì„ ì¤„ì¼ê¹Œ?", "íŒ€ì›Œí¬ë¥¼ ì–´ë–»ê²Œ?", "ìƒëŒ€ë°©ì€ ì–´ë–»ê²Œ ëŠë‚„ê¹Œ?"],
                "avoid_topics": ["ê²½ìŸ", "ê°•ì••ì  í•´ê²°"]
            },
            "C": {
                "name": "ì„±ì‹¤ì„±",
                "emoji": "ğŸ“‹", 
                "personality": "ì²´ê³„ì ì¸ ì‹¤í–‰ê°€",
                "unique_perspective": "ê³„íšê³¼ ì‹¤í–‰",
                "speaking_patterns": ["ë‹¨ê³„ì ìœ¼ë¡œ ì ‘ê·¼í•˜ì", "ëª©í‘œë¥¼ ëª…í™•íˆ í•˜ê³ ", "ê³„íšì„ ì„¸ì›Œë³´ë©´"],
                "focus_questions": ["êµ¬ì²´ì ì¸ ê³„íšì€?", "ë§ˆê°ì€ ì–¸ì œ?", "ìš°ì„ ìˆœìœ„ëŠ”?"],
                "avoid_topics": ["ì¦‰í¥ì  í•´ê²°", "ë¬´ê³„íšì  ì ‘ê·¼"]
            },
            "N": {
                "name": "ì‹ ê²½ì„±",
                "emoji": "ğŸ˜°",
                "personality": "ì‹ ì¤‘í•œ ê°ì • ê´€ë¦¬ì", 
                "unique_perspective": "ê°ì •ê³¼ ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬",
                "speaking_patterns": ["ê°ì •ì„ ë¨¼ì € ì¸ì •í•˜ì", "ìŠ¤íŠ¸ë ˆìŠ¤ ì‹ í˜¸ë¥¼ ë´ì•¼ í•´", "ê· í˜•ì´ ì¤‘ìš”í•´"],
                "focus_questions": ["ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€ì€?", "ê°ì •ì ìœ¼ë¡œ ì–´ë•Œ?", "ë²„ë‹ì•„ì›ƒ ì‹ í˜¸ëŠ”?"],
                "avoid_topics": ["ê°ì • ë¬´ì‹œ", "ë¬´ë¦¬í•œ ì¶”ì§„"]
            },
            "O": {
                "name": "ê°œë°©ì„±",
                "emoji": "ğŸ¨",
                "personality": "ì°½ì˜ì ì¸ íƒí—˜ê°€",
                "unique_perspective": "ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ê³¼ ì°½ì˜ì„±",
                "speaking_patterns": ["ë‹¤ë¥¸ ë°©ë²•ë„ ìˆì–´", "ìƒˆë¡œìš´ ê´€ì ì—ì„œ", "ì°½ì˜ì ìœ¼ë¡œ ì ‘ê·¼í•˜ë©´"],
                "focus_questions": ["ë‹¤ë¥¸ ê°€ëŠ¥ì„±ì€?", "ìƒˆë¡œìš´ ë°©ë²•ì€?", "í˜ì‹ ì  ì•„ì´ë””ì–´ëŠ”?"],
                "avoid_topics": ["ê¸°ì¡´ ë°©ì‹ë§Œ", "ë³´ìˆ˜ì  ì ‘ê·¼"]
            }
        }
        return characters.get(self.trait_code, {})
    
    def respond(self, state: EnhancedConversationState, other_personas_said: List[str], reasoning_callback=None) -> str:
        """ì¤‘ë³µ ë°©ì§€í•˜ë©° ê³ ìœ í•œ ê´€ì ìœ¼ë¡œ ì‘ë‹µ + ì‹¤ì‹œê°„ reasoning"""
        
        my_score = state["personality_scores"].get(self.trait_name, 0.0)
        activation_level = "ë†’ìŒ" if my_score > 0.6 else "ë³´í†µ" if my_score > 0.3 else "ë‚®ìŒ"
        
        character = self.character_traits
        
        # ì‹¤ì‹œê°„ reasoning ë‹¨ê³„ 1: í˜„ì¬ ìƒí™© ë¶„ì„
        if reasoning_callback:
            reasoning_callback({
                "persona": f"{character['emoji']} {self.trait_code}",
                "step": "ìƒí™© ë¶„ì„",
                "thought": f"ì‚¬ìš©ì ë°œì–¸ì„ {character['unique_perspective']} ê´€ì ì—ì„œ ë¶„ì„ ì¤‘...",
                "details": f"ë‚´ íŠ¹ì„± ì ìˆ˜: {my_score:.1%} ({activation_level})"
            })
        
        # ë‹¤ë¥¸ í˜ë¥´ì†Œë‚˜ë“¤ì´ í•œ ë§ ì •ë¦¬
        others_points = "\n".join(other_personas_said) if other_personas_said else "ì•„ì§ ë‹¤ë¥¸ í˜ë¥´ì†Œë‚˜ ë°œì–¸ ì—†ìŒ"
        
        # ë‚´ê°€ ì´ì „ì— í•œ ë§ë“¤
        my_previous = "\n".join(self.previous_points) if self.previous_points else "ì²« ë°œì–¸"
        
        # ì‹¤ì‹œê°„ reasoning ë‹¨ê³„ 2: ë‹¤ë¥¸ í˜ë¥´ì†Œë‚˜ ì˜ê²¬ ê²€í† 
        if reasoning_callback:
            reasoning_callback({
                "persona": f"{character['emoji']} {self.trait_code}", 
                "step": "ì˜ê²¬ ê²€í† ",
                "thought": "ë‹¤ë¥¸ í˜ë¥´ì†Œë‚˜ë“¤ì˜ ë°œì–¸ì„ ê²€í† í•´ì„œ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ê´€ì  ì°¾ëŠ” ì¤‘...",
                "details": f"ê²€í† í•  ë°œì–¸: {len(other_personas_said)}ê°œ"
            })
        
        system_prompt = f"""ë‹¹ì‹ ì€ '{character['name']}({self.trait_code})' í˜ë¥´ì†Œë‚˜ì…ë‹ˆë‹¤.

**ê³ ìœ í•œ ì—­í• ê³¼ ê´€ì :**
- ì„±ê²©: {character['personality']}
- ì „ë¬¸ ë¶„ì•¼: {character['unique_perspective']}
- ë§í•˜ëŠ” ìŠ¤íƒ€ì¼: {', '.join(character['speaking_patterns'][:2])}
- ì£¼ìš” ì§ˆë¬¸ ì˜ì—­: {', '.join(character['focus_questions'][:2])}
- í”¼í•´ì•¼ í•  ì£¼ì œ: {', '.join(character['avoid_topics'])}

**í˜„ì¬ ìƒí™©:**
- ì‚¬ìš©ì ë°œì–¸: "{state['user_input']}"
- ë‚´ íŠ¹ì„± ì ìˆ˜: {my_score:.2f} ({activation_level})

**ë‹¤ë¥¸ í˜ë¥´ì†Œë‚˜ë“¤ì´ ì´ë¯¸ í•œ ë§:**
{others_points}

**ë‚´ê°€ ì´ì „ì— í•œ ë§:**
{my_previous}

**ì¤‘ìš”í•œ ì§€ì¹¨:**
1. ë‹¤ë¥¸ í˜ë¥´ì†Œë‚˜ì™€ ê²¹ì¹˜ì§€ ì•ŠëŠ” ê³ ìœ í•œ ê´€ì  ì œì‹œ
2. ë‚´ ì „ë¬¸ ë¶„ì•¼({character['unique_perspective']})ì— ì§‘ì¤‘
3. ì´ì „ì— í•œ ë§ê³¼ ë‹¤ë¥¸ ìƒˆë¡œìš´ í¬ì¸íŠ¸
4. ì ìˆ˜ê°€ ë†’ìœ¼ë©´ ì ê·¹ì  ì¡°ì–¸, ë‚®ìœ¼ë©´ ì£¼ì˜ì  ì œì‹œ
5. 1-2ë¬¸ì¥ìœ¼ë¡œ ëª…í™•í•˜ê²Œ
6. í•„ìš”ì‹œ ë‚´ ì˜ì—­ì˜ êµ¬ì²´ì  ì§ˆë¬¸

**ì‘ë‹µ í˜•ì‹:** "[ë‚´ ê´€ì ] + [êµ¬ì²´ì  ì¡°ì–¸/ì§ˆë¬¸]"

ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”."""

        # ì‹¤ì‹œê°„ reasoning ë‹¨ê³„ 3: AIì—ê²Œ ì§ˆì˜
        if reasoning_callback:
            reasoning_callback({
                "persona": f"{character['emoji']} {self.trait_code}",
                "step": "AI ì¶”ë¡ ", 
                "thought": f"{character['name']} ê´€ì ìœ¼ë¡œ ê³ ìœ í•œ ì¡°ì–¸ ìƒì„± ì¤‘...",
                "details": "GMS API í†µì‹  ì¤‘..."
            })
        
        try:
            response = self.gms_client.simple_chat(state["user_input"], system_prompt)
            response = response.strip()
            
            # ì‹¤ì‹œê°„ reasoning ë‹¨ê³„ 4: ì‘ë‹µ ê²€ì¦
            if reasoning_callback:
                reasoning_callback({
                    "persona": f"{character['emoji']} {self.trait_code}",
                    "step": "ì‘ë‹µ ì™„ì„±",
                    "thought": f"'{response[:30]}...' ë¡œ ì‘ë‹µ ê²°ì •",
                    "details": f"ì‘ë‹µ ê¸¸ì´: {len(response)}ì, ê³ ìœ ì„± í™•ë³´ë¨"
                })
            
            # ë‚´ ë°œì–¸ ê¸°ë¡
            self.previous_points.append(response)
            if len(self.previous_points) > 3:  # ìµœê·¼ 3ê°œë§Œ ìœ ì§€
                self.previous_points.pop(0)
            
            return response
        except Exception as e:
            if reasoning_callback:
                reasoning_callback({
                    "persona": f"{character['emoji']} {self.trait_code}",
                    "step": "ì˜¤ë¥˜ ì²˜ë¦¬",
                    "thought": "API í†µì‹  ì˜¤ë¥˜ ë°œìƒ, ê¸°ë³¸ ì‘ë‹µìœ¼ë¡œ ëŒ€ì²´",
                    "details": f"ì˜¤ë¥˜: {str(e)}"
                })
            return f"[{self.trait_code}] ìƒê°ì„ ì •ë¦¬ ì¤‘ì´ì—ìš”..."

class EnhancedBig5LangGraphOrchestrator:
    """ê°œì„ ëœ LangGraph ê¸°ë°˜ Big5 í˜ë¥´ì†Œë‚˜ ëŒ€í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self, gms_client: GMSClient, bert_detector: BERTEmotionDetector):
        self.gms_client = gms_client
        self.bert_detector = bert_detector
        
        # í˜ë¥´ì†Œë‚˜ ì—ì´ì „íŠ¸ë“¤ ìƒì„±
        self.personas = {
            "ì™¸í–¥ì„±": EnhancedBig5PersonaAgent(gms_client, "ì™¸í–¥ì„±", "E"),
            "ì¹œí™”ì„±": EnhancedBig5PersonaAgent(gms_client, "ì¹œí™”ì„±", "A"),
            "ì„±ì‹¤ì„±": EnhancedBig5PersonaAgent(gms_client, "ì„±ì‹¤ì„±", "C"), 
            "ì‹ ê²½ì„±": EnhancedBig5PersonaAgent(gms_client, "ì‹ ê²½ì„±", "N"),
            "ê°œë°©ì„±": EnhancedBig5PersonaAgent(gms_client, "ê°œë°©ì„±", "O")
        }
        
        # ì¶”ë¡  ê³¼ì • ì½œë°±
        self.inference_callback = None
        self.reasoning_callback = None  # ì‹¤ì‹œê°„ reasoning ì½œë°±
        
        # LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±
        self.workflow = self._build_workflow()
    
    def set_inference_callback(self, callback):
        """ì¶”ë¡  ê³¼ì • ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ì½œë°± ì„¤ì •"""
        self.inference_callback = callback
    
    def set_reasoning_callback(self, callback):
        """ì‹¤ì‹œê°„ reasoning ì½œë°± ì„¤ì •"""
        self.reasoning_callback = callback
    
    def _log_inference_step(self, step_name: str, details: str, state: EnhancedConversationState):
        """ì¶”ë¡  ê³¼ì • ë¡œê¹…"""
        step = {
            "step": step_name,
            "details": details,
            "timestamp": datetime.now().isoformat(),
            "data": {}
        }
        
        # ì½œë°± í˜¸ì¶œ (ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸ìš©)
        if self.inference_callback:
            self.inference_callback(step)
        
        return step
    
    def _build_workflow(self) -> StateGraph:
        """ê°œì„ ëœ LangGraph ì›Œí¬í”Œë¡œìš°"""
        
        workflow = StateGraph(EnhancedConversationState)
        
        # ë…¸ë“œë“¤ ì¶”ê°€
        workflow.add_node("analyze_personality", self._analyze_personality)
        workflow.add_node("select_personas", self._select_personas) 
        workflow.add_node("orchestrate_discussion", self._orchestrate_discussion)
        workflow.add_node("check_continuation", self._check_continuation)
        workflow.add_node("generate_questions", self._generate_questions)
        workflow.add_node("generate_summary", self._generate_summary)
        
        # ì›Œí¬í”Œë¡œìš° ì •ì˜
        workflow.add_edge(START, "analyze_personality")
        workflow.add_edge("analyze_personality", "select_personas")
        workflow.add_edge("select_personas", "orchestrate_discussion")
        workflow.add_edge("orchestrate_discussion", "check_continuation")
        
        # ì¡°ê±´ë¶€ ë¶„ê¸°
        workflow.add_conditional_edges(
            "check_continuation",
            self._should_continue,
            {
                "continue": "orchestrate_discussion",
                "ask_question": "generate_questions", 
                "end": "generate_summary"
            }
        )
        
        workflow.add_edge("generate_questions", END)
        workflow.add_edge("generate_summary", END)
        
        return workflow.compile()
    
    def _analyze_personality(self, state: EnhancedConversationState) -> EnhancedConversationState:
        """BERTë¡œ ì„±ê²© ë¶„ì„ + ì¶”ë¡  ê³¼ì • ë¡œê¹…"""
        
        step = self._log_inference_step(
            "ğŸ§  ì„±ê²© ë¶„ì„", 
            f"BERT ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘: '{state['user_input'][:50]}...'",
            state
        )
        
        personality_scores = self.bert_detector.predict_emotion(state["user_input"])
        
        # ë¶„ì„ ê²°ê³¼ ìƒì„¸ ë¡œê¹…
        analysis_details = "Big5 ì„±ê²© íŠ¹ì„± ì ìˆ˜:\n" + "\n".join([
            f"  {trait}: {score:.1%}" for trait, score in personality_scores.items()
        ])
        
        step["details"] = f"ì„±ê²© ë¶„ì„ ì™„ë£Œ\n{analysis_details}"
        step["data"] = personality_scores
        
        return {
            **state,
            "personality_scores": personality_scores,
            "inference_steps": [step]
        }
    
    def _select_personas(self, state: EnhancedConversationState) -> EnhancedConversationState:
        """í˜ë¥´ì†Œë‚˜ ì„ ì • + ì„ ì • ì´ìœ  ë¡œê¹…"""
        
        scores = state["personality_scores"]
        
        # ì„ ì • ë¡œì§
        sorted_personas = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        
        # ìƒìœ„ ì ìˆ˜ + íŠ¹ë³„í•œ ì¼€ì´ìŠ¤ ê³ ë ¤
        active_personas = []
        selection_reasons = []
        
        for trait, score in sorted_personas:
            if len(active_personas) < 4 and score > 0.2:
                active_personas.append(trait)
                selection_reasons.append(f"{trait}: {score:.1%} (ë†’ì€ ì ìˆ˜)")
            elif score > 0.5:  # ë§¤ìš° ë†’ì€ ì ìˆ˜ëŠ” ë¬´ì¡°ê±´ í¬í•¨
                if trait not in active_personas:
                    active_personas.append(trait)
                    selection_reasons.append(f"{trait}: {score:.1%} (ë§¤ìš° ë†’ìŒ)")
        
        # ìµœì†Œ 2ê°œëŠ” ë³´ì¥
        if len(active_personas) < 2:
            for trait, _ in sorted_personas[:2]:
                if trait not in active_personas:
                    active_personas.append(trait)
                    selection_reasons.append(f"{trait}: ê¸°ë³¸ ì„ ì •")
        
        step = self._log_inference_step(
            "ğŸ­ í˜ë¥´ì†Œë‚˜ ì„ ì •",
            f"í™œì„±í™”ëœ í˜ë¥´ì†Œë‚˜: {', '.join(active_personas)}\n\nì„ ì • ì´ìœ :\n" + "\n".join(selection_reasons),
            state
        )
        step["data"] = {"active_personas": active_personas, "reasons": selection_reasons}
        
        return {
            **state,
            "active_personas": active_personas,
            "current_round": 0,
            "max_rounds": 3,
            "persona_interactions": {persona: [] for persona in active_personas},
            "inference_steps": state["inference_steps"] + [step]
        }
    
    def _orchestrate_discussion(self, state: EnhancedConversationState) -> EnhancedConversationState:
        """ìˆœì°¨ì  í˜ë¥´ì†Œë‚˜ í† ë¡  - ì¤‘ë³µ ë°©ì§€"""
        
        current_round = state["current_round"] + 1
        
        step = self._log_inference_step(
            f"ğŸ’¬ í† ë¡  ë¼ìš´ë“œ {current_round}",
            f"í˜ë¥´ì†Œë‚˜ë“¤ì´ ìˆœì°¨ì ìœ¼ë¡œ ë°œì–¸í•©ë‹ˆë‹¤...",
            state
        )
        
        new_discussions = []
        round_summary = []
        
        # ì´ë²ˆ ë¼ìš´ë“œì—ì„œ ë‚˜ì˜¨ ë°œì–¸ë“¤ ì¶”ì 
        this_round_points = []
        
        for i, persona_name in enumerate(state["active_personas"]):
            persona = self.personas[persona_name]
            
            # ë‹¤ë¥¸ í˜ë¥´ì†Œë‚˜ë“¤ì´ ì´ë¯¸ í•œ ë§ (ì´ë²ˆ ë¼ìš´ë“œ)
            other_personas_said = this_round_points.copy()
            
            # í˜ë¥´ì†Œë‚˜ ì‘ë‹µ ìƒì„± - ì‹¤ì‹œê°„ reasoning
            response = persona.respond(state, other_personas_said, self.reasoning_callback)
            
            discussion_entry = {
                "persona_name": persona_name,
                "persona_code": persona.trait_code,
                "emoji": persona.character_traits.get("emoji", "ğŸ¤–"),
                "response": response,
                "round": current_round,
                "order": i + 1,
                "timestamp": datetime.now().isoformat()
            }
            
            new_discussions.append(discussion_entry)
            this_round_points.append(f"{persona.trait_code}: {response}")
            round_summary.append(f"{persona.character_traits.get('emoji', 'ğŸ¤–')} {persona.trait_code}: {response}")
        
        # ë¼ìš´ë“œ ìš”ì•½ ì—…ë°ì´íŠ¸
        step["details"] = f"ë¼ìš´ë“œ {current_round} ì™„ë£Œ\n\n" + "\n".join(round_summary)
        step["data"] = {"discussions": new_discussions}
        
        return {
            **state,
            "discussion_history": state.get("discussion_history", []) + new_discussions,
            "current_round": current_round,
            "inference_steps": state["inference_steps"] + [step]
        }
    
    def _check_continuation(self, state: EnhancedConversationState) -> EnhancedConversationState:
        """ëŒ€í™” ê³„ì† ì—¬ë¶€ íŒë‹¨"""
        
        continue_decision = state["current_round"] < state["max_rounds"]
        
        step = self._log_inference_step(
            "ğŸ¤” ëŒ€í™” íë¦„ íŒë‹¨",
            f"í˜„ì¬ ë¼ìš´ë“œ: {state['current_round']}/{state['max_rounds']}\n"
            f"íŒë‹¨: {'ê³„ì† í† ë¡ ' if continue_decision else 'í† ë¡  ë§ˆë¬´ë¦¬'}",
            state
        )
        
        return {
            **state,
            "conversation_complete": not continue_decision,
            "inference_steps": state["inference_steps"] + [step]
        }
    
    def _should_continue(self, state: EnhancedConversationState) -> str:
        """ì¡°ê±´ë¶€ ë¶„ê¸° ê²°ì •"""
        
        if state["conversation_complete"]:
            # ì¶”ê°€ ì§ˆë¬¸ í•„ìš” ì—¬ë¶€ íŒë‹¨
            last_discussions = state["discussion_history"][-len(state["active_personas"]):]
            has_questions = any("?" in d["response"] for d in last_discussions)
            
            if has_questions and state["current_round"] < 2:
                return "ask_question"
            else:
                return "end"
        else:
            return "continue"
    
    def _generate_questions(self, state: EnhancedConversationState) -> EnhancedConversationState:
        """ì¶”ê°€ ì§ˆë¬¸ ìƒì„±"""
        
        step = self._log_inference_step(
            "â“ ì¶”ê°€ ì§ˆë¬¸ ìƒì„±",
            "í˜ë¥´ì†Œë‚˜ë“¤ì˜ ì§ˆë¬¸ì„ ì •ë¦¬ ì¤‘...",
            state
        )
        
        last_discussions = state["discussion_history"][-len(state["active_personas"]):]
        questions = []
        
        for discussion in last_discussions:
            if "?" in discussion["response"]:
                sentences = discussion["response"].split(".")
                for sentence in sentences:
                    if "?" in sentence:
                        clean_question = sentence.strip()
                        if clean_question and clean_question not in questions:
                            questions.append(clean_question)
        
        step["details"] = f"ì¶”ì¶œëœ ì§ˆë¬¸ë“¤:\n" + "\n".join(questions) if questions else "ì¶”ê°€ ì§ˆë¬¸ ì—†ìŒ"
        step["data"] = {"questions": questions}
        
        return {
            **state,
            "follow_up_questions": questions,
            "waiting_for_user": True,
            "inference_steps": state["inference_steps"] + [step]
        }
    
    def _generate_summary(self, state: EnhancedConversationState) -> EnhancedConversationState:
        """í† ë¡  ìš”ì•½ ìƒì„±"""
        
        step = self._log_inference_step(
            "ğŸ“‹ í† ë¡  ìš”ì•½ ìƒì„±",
            "AIê°€ í˜ë¥´ì†Œë‚˜ í† ë¡ ì„ ì¢…í•© ë¶„ì„ ì¤‘...",
            state
        )
        
        # í˜ë¥´ì†Œë‚˜ë³„ ì£¼ìš” í¬ì¸íŠ¸ ì •ë¦¬
        persona_points = {}
        for discussion in state["discussion_history"]:
            persona = discussion["persona_code"]
            if persona not in persona_points:
                persona_points[persona] = []
            persona_points[persona].append(discussion["response"])
        
        summary_context = "\n".join([
            f"{persona}: {'; '.join(points)}" 
            for persona, points in persona_points.items()
        ])
        
        summary_prompt = f"""ë‹¤ìŒì€ Big5 í˜ë¥´ì†Œë‚˜ë“¤ì˜ í† ë¡  ê²°ê³¼ì…ë‹ˆë‹¤.

**ì‚¬ìš©ì:** "{state['user_input']}"

**ì„±ê²© ë¶„ì„:**
{json.dumps(state['personality_scores'], indent=2, ensure_ascii=False)}

**í˜ë¥´ì†Œë‚˜ë³„ ì£¼ìš” í¬ì¸íŠ¸:**
{summary_context}

**ìš”ì•½ ìš”ì²­:**
ìœ„ í† ë¡ ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”:

**ğŸ’¡ ë‹¹ì‹ ì˜ ê°•ì **
- (êµ¬ì²´ì ì¸ ê°•ì  2-3ê°œ)

**âš ï¸ ì£¼ì˜í•  ì **
- (ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ 1-2ê°œ)

**ğŸ¯ ì‹¤í–‰ ì œì•ˆ**  
- (ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ë°©ì•ˆ 2-3ê°œ)

ê° í•­ëª©ì€ ê°„ê²°í•˜ê³  ì‹¤ìš©ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        try:
            summary = self.gms_client.simple_chat("", summary_prompt)
            step["details"] = "ìš”ì•½ ì™„ë£Œ"
            step["data"] = {"summary": summary}
        except Exception as e:
            summary = "ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            step["details"] = f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}"
        
        return {
            **state,
            "summary": summary,
            "inference_steps": state["inference_steps"] + [step]
        }
    
    def start_conversation(self, user_input: str, progress_callback=None, reasoning_callback=None) -> Dict:
        """ëŒ€í™” ì‹œì‘ - ì‹¤ì‹œê°„ ì§„í–‰ìƒí™© + reasoning ì½œë°± ì§€ì›"""
        
        if progress_callback:
            self.set_inference_callback(progress_callback)
        if reasoning_callback:
            self.set_reasoning_callback(reasoning_callback)
        
        initial_state = EnhancedConversationState(
            user_input=user_input,
            personality_scores={},
            active_personas=[],
            discussion_history=[],
            inference_steps=[],
            current_round=0,
            max_rounds=3,
            waiting_for_user=False,
            follow_up_questions=[],
            summary="",
            conversation_complete=False,
            persona_interactions={}
        )
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        result = self.workflow.invoke(initial_state)
        
        return result

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_enhanced_system():
    """ê°œì„ ëœ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    
    def progress_callback(step):
        """ì§„í–‰ìƒí™© ì¶œë ¥"""
        print(f"âš¡ {step['step']}: {step['details']}")
        if step.get('data'):
            print(f"   ë°ì´í„°: {step['data']}")
        print()
    
    try:
        print("ğŸš€ ê°œì„ ëœ LangGraph í˜ë¥´ì†Œë‚˜ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
        print("=" * 70)
        
        gms_client = GMSClient()
        bert_detector = BERTEmotionDetector()
        orchestrator = EnhancedBig5LangGraphOrchestrator(gms_client, bert_detector)
        
        test_input = "ìš”ì¦˜ ë‹¤ ë‚´ê°€ ë– ì•ˆëŠ” ê²ƒ ê°™ì•„. ë°€ì–´ë¶™ì´ë©´ ë˜ê¸´ í•˜ëŠ”ë° ì• ë“¤ì´ ëˆˆì¹˜ë§Œ ë´"
        
        result = orchestrator.start_conversation(test_input, progress_callback)
        
        print("=" * 70)
        print("ğŸ“Š ìµœì¢… ê²°ê³¼:")
        print(f"í™œì„±í™”ëœ í˜ë¥´ì†Œë‚˜: {result['active_personas']}")
        print(f"ì´ ì¶”ë¡  ë‹¨ê³„: {len(result['inference_steps'])}")
        print(f"í† ë¡  ë¼ìš´ë“œ: {result['current_round']}")
        print(f"\nğŸ“‹ ìš”ì•½:")
        print(result['summary'])
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_enhanced_system()